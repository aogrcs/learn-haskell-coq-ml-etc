Created       : 2015 Jul 27 (Mon) 07:34:11 by Harold Carr.
Last Modified : 2015 Jul 28 (Tue) 09:07:06 by Harold Carr.

http://redex.racket-lang.org/

MORNING:

Course Outline:
- [[ccs.neu.edu/home/matthias/redex-workshop]]

λ = `^

((λx.x) (λx.x))
- this is NOT text: think TREES

vars : what matters is their binding
- =α : set of all lambda exprs that are equivalent (var renaming)

substitution (binding)
- (λx.e) e = e[x<-e']
- but are the args well-defined? (are the functions partial?)

β axiom
- notion of reduction
- compatible closure of ??
- if e β e' then e =β e'

REducible EXpression

syntaic compatiblity closure
- if e β e' then e0 e =β e0 e' (shift right)
- if e β e' then e e0 =β e' e0 (shift left)

reflexive, symmetric, transitive are algebraic functions that can be applied to relations

system of calculating equivalences between terms

does it have meaning?
- can I equate 'true' and 'false' - if so then inconsistent
  - prove you can't prove the equivalence of ANY two terms
  - church-rosser (consistency theorem)
- is there a topological generated spae of functions that assigned
  meaning to terms and satisfies equations?

1958

- λ Calculus and Denotational Semantic had BAD influence on CS
- LISP introduced λ notation and got it wrong
- Algol60 supposed to based on substitution model of lambda calculus (call-by-name)
  - supposed to be β rule of λ calculus
    - but slow
  - so introduced call-by-value (fast, but did not understand it)

Landin (B"ohm, McCarthy) wrote how to interpret Algo60 in λ calculus

Can't define "applicative order evaluation"
- but was popularized: Abelson/Sussman book
- to do it, defined reduction equations - has not been done

Denotational semantics took us off track.
- looking for topologies was waste of time

1972

Plotkin published "Call-by-name, call-by-value and the λ calculus"
- algorithm to understand calculus and semantic for programming language
- connected CBN/CBV (CPS)
Plotkin's 8-step program:
1. pick a term language, scoped : e.g., e = x | λx.e | e e
2. pick a subset of terms called programs and another called values
   - programs are closed terms (no free variables)
   - values are λ exprs or other constants (e.g., numbers ) of language
3. define a notion of reduction
   - basic relation that relates terms
   - Plotkin picked β and βᵥ : (λx,e)v βᵥ e[x <- v]
4. uniformly create a calculus (̄=ₓ) fro the notions of reduction (xₓ)
   - a way of equating arbitary program FRAGMENTS
5. define a semantics from  xₓ
   - evalₓ : Program x Value
   - e evalₓ v iff e xₓ v
   - a way of relating COMPLETE programs to values
6. prove evalₓ is a function
   - church-rosser lemma is central
   - evalₓ is a (partial) function
   - the reason a λ expr prints like #closure is because it will evaluate to DIFFERENT things
     (therefore not a function) depending on compiler optimizations
(Y operator is good for humans, not for the machine)
7. prove =ₓ satisfies a "standardization" property
   - if e =ₓ e' then can be done in algorithmic fashion
   - how to pick next REDEX
   - pick leftmost/outermost REDEX (unless skipped before)
   - standard reduction relation : |->ₓ
     - (instead of search the space and pick one you like)
   - evalₓ (e) = v iff e ->ₓ v
   - this eval is same as Landin used for CBV
   - now have calculation system that enables reasoning about programs
   - evalₓ based on standard reduction (partial programs)
   - eval=ₓ based on ?? (calculations on programs)
(book by Halmos : how to write mathematics - make sure paper can be read out loud)
(curry and fess theorem)
8. prove evalₓ = eval=ₓ
   - consistent with "fast" interpretation
   - Morris '68 : programming language based on typed polymorphic λ calculus
   - OBSERVATIONAL EQUIVALENCE
     - for all ways of placing a term into a complete program : a CONTEXT
     - a program with a HOLE where an expression goes C[e] viz C[e']
   - prove evalₓ (C[e]) = evalₓ (C[e'])
     - EXTENTIONAL: cannot tell from TERMINATION value the difference between the two
     - (INTENTIONAL does not matter, e.g., insert versus quick sort)
   - =~ and =ᵥ
   - proof system consistent with "the truth"

This week: using these 8 points to create models of languages and build interpreters.

CBV and CBN are NOT related otherwise than in syntax of the terms.

Laziness is a very complicated reductio.

1985 : Mattheis

(f (call/cc g)) ~ g(f)  WRONG
- call/cc : imperative way controlling execution

Evaluation Context Semantics (much shorter than inferene rules)
- 1st INSIGHT: USE CONTEXTS INSTEAD OF INFERENCE RULES (e.g., e β e' => e =β e)
- true for syntactic compatibility and notion of leftmost/outermost

CONTEXTS
- a program with a ONE HOLE where you can put an expression

e = x    | λx.e | e e
    HOLE | λx.E | C e | e C

generate terms with ONE hole

What can you put in the hole? (filling in a context).
C[e] "textually" put e into hole

Rather than inference rules:
  =β : e =β e' iff [∃c . e = C[(λx.e₀)E₁] AND e' = C[e₀[x<-E₁]]

Evaluation Context (write single eval step using contexts)

CBN: E = HOLE | (E e)
     E[(λx.e)e')] is the LMOM redex

     E[(λx.e)e'] ->name E[e[x<-e']]

CBV : E = HOLE | (v E) | (E e)  : left to right
      or  HOLE | (e E) | (E v)  : right to left

     E[(λx.e)v] ->value E[e[x<-v]]

2nd INSIGHT : you can use evaluation context in statement of reduction
- useful for non-local flow-of-control (exceptions, continuations, ...)

  E[cloud v] where cloud can manipulate E

System with Exceptions

SYNTAX:      e = x | λx.e | ee | raise e

CALCUATION:  C[(λx.e)v]    =ₓ C[e[x<-x]]
             C[E[raise e]] =ₓ C[raise e]

REDUCTION:   E[(λx.e)v]     ->ₓ E[e[x<-x]]
             E[E'[raise e]] ->ₓ E[raise e] ->ₓ raise e

System with Assignments

SYNTAX:      e = x | λx.e | ee | x := e aka (set! x e) | (letrec ((x v) ...) e)

EVALUATION CONTEXTS:
             v = λx.e
             E = HOLE | (E e) | (v e) | (set! x E)

CALCULUS:
βset!  : (λ.x)v R (letrec ((x v)) e)
(x)    : (letrec ((...(x v) ...)) E[x]) R (letrec ((.. (x v) ...) E[v]])
(set!) : (letrec ((...(x v) ...))E[set! x .....

(scope extrusion) : ... you can lift letrecs out

(merge) : letrec immediately inside letrec

all above is for SINGLE-THREADED

but can do reductions in parallel

3rd INSIGHT : derive register machines from standard

Separate E from the expr where the "machine" is looking for redex

control register : e
stack   register : E

change data represetation from context to stack (real stack)

while we search for next redex do next substitution  : make substitution lazy
yields a explicit environment

control + env (value of free vars) + control stack : CEK machine

THIS TAKES TO PAGE 173.  Part 1 without chapter 10.

------------------------------------------------------------------------------
AFTERNOON

Part 2: pieces of chapters 11-15 (except for Chapter 18)

- [[http://ccs.neu.edu/home/matthias/redex-workshop/lab-mon-aft.rkt]]
